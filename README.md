# CIFARâ€‘10Â ResNetâ€‘50Â Fineâ€‘TuningÂ +Â Gradâ€‘CAM

> Fineâ€‘tuning de **ResNetâ€‘50** preâ€‘entrenada en ImageNet sobre **CIFARâ€‘10** con interpretabilidad **Gradâ€‘CAM**.

![Gradâ€‘CAM sample](assets/gradcam_grid.gif)

---

## âœ¨Â CaracterÃ­sticas principales

| MÃ³dulo                  | DescripciÃ³n                                                                |
| ----------------------- | -------------------------------------------------------------------------- |
| **TransferÂ Learning**   | Carga de *weights* ImageNet, congelado selectivo y *unfreezing* progresivo |
| **Aumento de datos**    | `RandomCrop`, `RandAugment`, `CutMix`, normalizaciÃ³n CIFARâ€‘10              |
| **OptunaÂ Search**       | BÃºsqueda bayesiana de `lr`, *weightâ€‘decay*, *dropout* y scheduler          |
| **Schedulers**          | `CosineAnnealingWarmRestarts` + *LR finder* automÃ¡tico                     |
| **EarlyÂ Stopping**      | Basado en *validationÂ accuracy* con *patience* adaptativo                  |
| **Gradâ€‘CAM**            | Mapas de activaciÃ³n por clase (capa `layer4`) exportados como PNG y GIF    |
| **MÃ©tricas & Matrices** | Accuracy, Precision, Recall, F1 + matriz de confusiÃ³n Plotly               |

---

## ğŸ“‚Â Estructura del proyecto

```text
cifar10-resnet-gradcam/
â”œâ”€â”€ data/                 # Descarga automÃ¡tica CIFARâ€‘10
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ datamodule.py     # PyTorchÂ Lightning DataModule
â”‚   â”œâ”€â”€ model.py          # ResNetâ€‘50 lightning module + Gradâ€‘CAM hooks
â”‚   â”œâ”€â”€ train.py          # Entrenamiento CLI
â”‚   â””â”€â”€ tune.py           # Optuna hyperâ€‘parameter search
â”œâ”€â”€ notebooks/            # AnÃ¡lisis EDA y visualizaciÃ³n Gradâ€‘CAM
â”œâ”€â”€ reports/              # Figuras, matrices, resultados CSV
â”œâ”€â”€ assets/               # ImÃ¡genes para README
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸Â Requisitos

```bash
python >= 3.9
pytorch >= 2.2
pytorchâ€‘lightning >= 2.2
optuna >= 3.6
albumentations
opencvâ€‘python
plotly scikitâ€‘learn rich tqdm
```

InstalaciÃ³n rÃ¡pida:

```bash
pip install -r requirements.txt
```

---

## ğŸš€Â Entrenamiento rÃ¡pido

```bash
# Fineâ€‘tuning con hiperparÃ¡metros por defecto
python src/train.py --epochs 30 --batch_size 128 --gpus 1

# BÃºsqueda de 40 ensayos con Optuna (â‰ˆ 2 h en una RTXÂ 3060)
python src/tune.py --trials 40 --timeout 7200
```

Los checkpoints y logs se guardan en `runs/`.

### VisualizaciÃ³n Gradâ€‘CAM

```bash
python notebooks/gradcam_demo.py --checkpoint <path_ckpt> --n_samples 10
```

Genera `gif` y `png` en `outputs/gradcam/`.

---

## ğŸ“ŠÂ Resultados

| MÃ©trica                | Valor             |
| ---------------------- | ----------------- |
| TestÂ Accuracy          | **88.2Â % Â±0.3**   |
| ParÃ¡metros entrenables | 23Â M              |
| Tiempo entrenamiento   | 28Â min (RTXÂ 3060) |

*ComparaciÃ³n completa y curva de aprendizaje en `reports/`.*

---

## ğŸï¸Â Eficiencia

| ConfiguraciÃ³n         | FPS entrenamiento | FPS inferencia |
| --------------------- | ----------------- | -------------- |
| Fullâ€‘precision        | 480               | 1Â 200          |
| MixedÂ precision (AMP) | **830**           | **2Â 050**      |

---

## ğŸ“œÂ Licencia

Distribuido bajo licencia MIT Â© 2025 **FernandoÂ NasserEddineÂ LÃ³pez**.

---

## ğŸ™ŒÂ CrÃ©ditos

* [PyTorchÂ Lightning](https://lightning.ai/)
* [Optuna](https://optuna.org/)
* [Gradâ€‘CAM](https://github.com/jacobgil/pytorch-grad-cam)
* Dataset [CIFARâ€‘10](https://www.cs.toronto.edu/~kriz/cifar.html) (KrizhevskyÂ 2009)

Si este cÃ³digo te resulta Ãºtil, Â¡no olvides dejarme un â­ï¸!
